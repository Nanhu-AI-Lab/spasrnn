# config.ini
[paths]
; root dir for saving logs and checkpoint
out_dir = ./logs
; mlflow tracking url
tracking_url = http://mlflow.nhnao.com:80
; Your ID shows in mlflow, PLEASE remember to CHANGE
logger_name = your_name

[para]
; dataset name. imdb, agnews, yelp etc.
dataset = agnews
; batch size, agnews 32, imdb 128
b = 32
; learning rate, agnews 2e-4, imdb 2e-3
lr = 2e-4
; number of total epochs to run
epochs = 50
; use which optimizer. SDG or Adam
opt = Adam
; parameter_1 for t_window beta in dense2sparse
time_step = 1e-3
; parameter_2 for t_window beta in dense2sparse
tau_mem = 1e-2
; cal aplha window for dense2sparse
alpha_window = 1e-3
; the using device, cpu or cuda'
device = cuda
; neuron number of hidden layer1
nb_hidden = 100
; neuron number of hidden layer2 (if exist)
nb_hidden2 = 200
; random seed number
seed = 1
; neuron firing threshold
th = 1.0
; dense2sparse surrogate width parameter
b_th = 0.8

; the reset mode of snn, default is hard, reset to zero; the soft is reset to (mem - V_th)
reset_m = soft
; the model to run, for now, there are 3 models can be chosen, d2s_snn, d2s_sRnn, slayer
model_name = d2s_sRnn
; the recurrent mode, fr means fully recurrent, sr means self recurrent
recurrent_mode = fr
; the mode of Readout module, for now, there are two modes can be chosen, mean and softmax
readout_mode = softmax
; aim_sentence_index
asi = 0

; embedding2srnn dropout probability
dropout_prob = 0.5
; number of embedding dim
nb_embedding = 100
; glove name
glove_name = 6B
; dataset split ratio
split_ratio = 0.7
; The minimum frequency needed to include a token in the vocabulary.
min_freq = 10

